{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.no_grad at 0x7ffaa8501e20>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.memory_game.game import Game\n",
    "from src.strategy.strategies import BaseStrategy, RandomPerfectMemory, TileMemory\n",
    "from src.models.cvmodel import CVModel\n",
    "from src.models.memory import TileRNN\n",
    "\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import collections, gc, resource\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "Cuda device count: 4\n"
     ]
    }
   ],
   "source": [
    "print(f'Cuda available: {torch.cuda.is_available()}')\n",
    "print(f'Cuda device count: {torch.cuda.device_count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "device = 3\n",
    "\n",
    "device = torch.device(f\"cuda:{device}\")\n",
    "print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_memory():\n",
    "    print('maxrss = {}'.format(\n",
    "        resource.getrusage(resource.RUSAGE_SELF).ru_maxrss))\n",
    "    tensors = collections.Counter(\n",
    "        (str(o.device), str(o.dtype), tuple(o.shape))\n",
    "        for o in gc.get_objects()\n",
    "        if torch.is_tensor(o)\n",
    "    )\n",
    "    for line in sorted(tensors.items()):\n",
    "        print('{}\\t{}'.format(*line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mem():\n",
    "    r = torch.cuda.memory_reserved(device)\n",
    "    a = torch.cuda.memory_allocated(device)\n",
    "    print(r-a, r, a)  # free inside reserved"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 20\n",
    "\n",
    "size_range = [[3,3], [4,4], [5,5]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_strategy(strategy, game):\n",
    "    win = False\n",
    "    while not win:\n",
    "        print('check1')\n",
    "        strategy.pick()\n",
    "        print('check2')\n",
    "        win, tot = game.check_win()\n",
    "        torch.cuda.empty_cache()\n",
    "    return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(n_trials, size_range, strategy, game):\n",
    "    data = []\n",
    "    for size in size_range:\n",
    "        data_size = []\n",
    "        for n in tqdm(range(n_trials), desc=f'Size: {size}'):\n",
    "            game.set_size(size)\n",
    "            strategy.reset()\n",
    "            tot = play_strategy(strategy, game)\n",
    "            data_size.append(math.log10(tot/np.prod(size)))\n",
    "        data.append(data_size)\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to '/home/ravi/datasets/coco-2017/validation' if necessary\n",
      "Found annotations at '/home/ravi/datasets/coco-2017/raw/instances_val2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading existing dataset 'coco-2017-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ravi/anaconda3/envs/torch/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "game = Game(\n",
    "            dataset_name='coco-2017', \n",
    "            split='validation', \n",
    "            field=\"ground_truth\", \n",
    "            ds_filter=F(\"supercategory\").is_in(('person', 'animal', 'food', 'vehicle', 'indoor')),\n",
    "            dataset_dir =\"/home/ravi/datasets/coco-2017\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs = BaseStrategy(game)\n",
    "# bs_data = collect_data(n_trials, size_range, bs, game)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rpm = RandomPerfectMemory(game)\n",
    "# rpm_data = collect_data(n_trials, size_range, rpm, game)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ravi/models/pytorch_vision_v0.10.0\n",
      "Size: [3, 3]:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55324160 134217728 78893568\n",
      "96756224 1107296256 1010540032\n",
      "40438272 1973420032 1932981760\n",
      "42181120 2898264064 2856082944\n",
      "41873920 3821010944 3779137024\n",
      "60205568 4762632192 4702426624\n",
      "61948416 5687476224 5625527808\n",
      "59544064 6608125952 6548581888\n",
      "77875712 7549747200 7471871488\n",
      "79618560 8474591232 8394972672\n",
      "77214208 9395240960 9318026752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: [3, 3]:   0%|          | 0/20 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 3; 10.76 GiB total capacity; 9.53 GiB already allocated; 13.25 MiB free; 9.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/ravi/Models-of-Working-Memory/random_pick.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3nmrarlibbhtsos6eubmuko7ydtqylmrnsa63qxwnnqiydmjm2ycjiyd.onion/home/ravi/Models-of-Working-Memory/random_pick.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m memory \u001b[39m=\u001b[39m TileRNN(\u001b[39m'\u001b[39m\u001b[39mlstm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1000\u001b[39m, \u001b[39m1000\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3nmrarlibbhtsos6eubmuko7ydtqylmrnsa63qxwnnqiydmjm2ycjiyd.onion/home/ravi/Models-of-Working-Memory/random_pick.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m tm \u001b[39m=\u001b[39m TileMemory(game, cvmodel, memory, distance_metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmanhattan\u001b[39m\u001b[39m'\u001b[39m, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B3nmrarlibbhtsos6eubmuko7ydtqylmrnsa63qxwnnqiydmjm2ycjiyd.onion/home/ravi/Models-of-Working-Memory/random_pick.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m tm_data \u001b[39m=\u001b[39m collect_data(n_trials, size_range, tm, game)\n",
      "\u001b[1;32m/home/ravi/Models-of-Working-Memory/random_pick.ipynb Cell 16\u001b[0m in \u001b[0;36mcollect_data\u001b[0;34m(n_trials, size_range, strategy, game)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3nmrarlibbhtsos6eubmuko7ydtqylmrnsa63qxwnnqiydmjm2ycjiyd.onion/home/ravi/Models-of-Working-Memory/random_pick.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     game\u001b[39m.\u001b[39mset_size(size)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3nmrarlibbhtsos6eubmuko7ydtqylmrnsa63qxwnnqiydmjm2ycjiyd.onion/home/ravi/Models-of-Working-Memory/random_pick.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     strategy\u001b[39m.\u001b[39mreset()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B3nmrarlibbhtsos6eubmuko7ydtqylmrnsa63qxwnnqiydmjm2ycjiyd.onion/home/ravi/Models-of-Working-Memory/random_pick.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     tot \u001b[39m=\u001b[39m play_strategy(strategy, game)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3nmrarlibbhtsos6eubmuko7ydtqylmrnsa63qxwnnqiydmjm2ycjiyd.onion/home/ravi/Models-of-Working-Memory/random_pick.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     data_size\u001b[39m.\u001b[39mappend(math\u001b[39m.\u001b[39mlog10(tot\u001b[39m/\u001b[39mnp\u001b[39m.\u001b[39mprod(size)))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3nmrarlibbhtsos6eubmuko7ydtqylmrnsa63qxwnnqiydmjm2ycjiyd.onion/home/ravi/Models-of-Working-Memory/random_pick.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m data\u001b[39m.\u001b[39mappend(data_size)\n",
      "\u001b[1;32m/home/ravi/Models-of-Working-Memory/random_pick.ipynb Cell 16\u001b[0m in \u001b[0;36mplay_strategy\u001b[0;34m(strategy, game)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3nmrarlibbhtsos6eubmuko7ydtqylmrnsa63qxwnnqiydmjm2ycjiyd.onion/home/ravi/Models-of-Working-Memory/random_pick.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m win:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3nmrarlibbhtsos6eubmuko7ydtqylmrnsa63qxwnnqiydmjm2ycjiyd.onion/home/ravi/Models-of-Working-Memory/random_pick.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     print_mem()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B3nmrarlibbhtsos6eubmuko7ydtqylmrnsa63qxwnnqiydmjm2ycjiyd.onion/home/ravi/Models-of-Working-Memory/random_pick.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     strategy\u001b[39m.\u001b[39;49mpick()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3nmrarlibbhtsos6eubmuko7ydtqylmrnsa63qxwnnqiydmjm2ycjiyd.onion/home/ravi/Models-of-Working-Memory/random_pick.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     win, tot \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mcheck_win()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3nmrarlibbhtsos6eubmuko7ydtqylmrnsa63qxwnnqiydmjm2ycjiyd.onion/home/ravi/Models-of-Working-Memory/random_pick.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m~/Models-of-Working-Memory/src/strategy/strategies.py:96\u001b[0m, in \u001b[0;36mTileMemory.pick\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpick\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m---> 96\u001b[0m     grid_repr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__update()\n\u001b[1;32m     97\u001b[0m     avail \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgame\u001b[39m.\u001b[39mget_avail()\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Models-of-Working-Memory/src/strategy/strategies.py:110\u001b[0m, in \u001b[0;36mTileMemory.__update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__update\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    109\u001b[0m     grid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgame\u001b[39m.\u001b[39mget_grid()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 110\u001b[0m     cv_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcvmodel(grid)\n\u001b[1;32m    111\u001b[0m     cv_out \u001b[39m=\u001b[39m cv_out\u001b[39m.\u001b[39mview(cv_out\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    112\u001b[0m     out, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory(cv_out, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Models-of-Working-Memory/src/models/cvmodel.py:22\u001b[0m, in \u001b[0;36mCVModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torchvision/models/resnet.py:276\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    274\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x)\n\u001b[1;32m    275\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(x)\n\u001b[0;32m--> 276\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer4(x)\n\u001b[1;32m    278\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[1;32m    279\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torchvision/models/resnet.py:97\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[1;32m     96\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(out)\n\u001b[0;32m---> 97\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn2(out)\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     identity \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    180\u001b[0m     bn_training,\n\u001b[1;32m    181\u001b[0m     exponential_average_factor,\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    183\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2451\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2452\u001b[0m )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 3; 10.76 GiB total capacity; 9.53 GiB already allocated; 13.25 MiB free; 9.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cvmodel = CVModel('pytorch/vision:v0.10.0', 'resnet18', model_dir='/home/ravi/models')\n",
    "memory = TileRNN('lstm', 1000, 1000)\n",
    "tm = TileMemory(game, cvmodel, memory, distance_metric='manhattan', device=device)\n",
    "tm_data = collect_data(n_trials, size_range, tm, game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_df = pd.melt(pd.DataFrame(bs_data).T, var_name='size', value_name='nclicks')\n",
    "bs_df['strategy'] = 'Random'\n",
    "\n",
    "rpm_df = pd.melt(pd.DataFrame(rpm_data).T, var_name='size', value_name='nclicks')\n",
    "rpm_df['strategy'] = 'Perfect memory'\n",
    "\n",
    "tm_df = pd.melt(pd.DataFrame(tm_data).T, var_name='size', value_name='nclicks')\n",
    "tm_df['strategy'] = 'LSTM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([bs_df, rpm_df, tm_df])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"size\", y='nclicks', hue=\"strategy\", kind=\"point\", \n",
    "            capsize=.15, data=data, aspect=1.5, errwidth=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
